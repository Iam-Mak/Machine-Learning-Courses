## Cost Function
Our cost function for logistic regression looks like:
![image](https://user-images.githubusercontent.com/92245436/147630911-d8ee043b-38fc-4cbb-86d0-f63d2b796135.png)
![image](https://user-images.githubusercontent.com/92245436/147630947-30ae5c24-f142-4837-a905-69074ff41b9b.png)
![image](https://user-images.githubusercontent.com/92245436/147630962-c02d6441-e5cb-4133-a5da-c609d1f6e271.png)

## Simplified Cost Function and Gradient Descent 
![image](https://user-images.githubusercontent.com/92245436/147631939-8e20004e-99c3-41ff-b39b-3aeb3dcac1c0.png)
![image](https://user-images.githubusercontent.com/92245436/147631954-2003d12f-05a3-4d31-bbd8-cf53f14f2a7d.png)

## Advanced Optimization
"Conjugate gradient", "BFGS", and "L-BFGS" are more sophisticated, faster ways to optimize Î¸ that can be used instead of gradient descent. We suggest that you should not write these more sophisticated algorithms yourself (unless you are an expert in numerical computing) but use the libraries instead, as they're already tested and highly optimized.
