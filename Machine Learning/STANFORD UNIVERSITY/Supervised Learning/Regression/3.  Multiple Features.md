## Multiple Features
Linear regression with multiple variables is also known as **"multivariate linear regression"**.

We now introduce notation for equations where we can have any number of input variables.
![image](https://user-images.githubusercontent.com/92245436/147384261-f43a6bcf-d995-41de-b5a3-1e33fe75042d.png) <br>
The multivariable form of the hypothesis function accommodating these multiple features is as follows:
![image](https://user-images.githubusercontent.com/92245436/147384297-38e0061a-afe7-4c4e-b252-d1544254f6c0.png)
![image](https://user-images.githubusercontent.com/92245436/147384301-0ce9a9f2-f2e7-400b-9c18-2fc77cf95edf.png) <br>
This is a vectorization of our hypothesis function for one training example; see the lessons on vectorization to learn more.
![image](https://user-images.githubusercontent.com/92245436/147384307-26aafc16-d2b4-400c-a990-53c20fb5ec33.png)

## Gradient Descent for Multiple Variables
The gradient descent equation itself is generally the same form; we just have to repeat it for our 'n' features:
![image](https://user-images.githubusercontent.com/92245436/147384347-87361615-8766-4472-83c2-c9f61a59c71e.png) <br>
In other words:

![image](https://user-images.githubusercontent.com/92245436/147384353-6f36318f-1660-4a9f-80e6-d56c95ee735f.png)

The following image compares gradient descent with one variable to gradient descent with multiple variables:
![image](https://user-images.githubusercontent.com/92245436/147384367-e0bcb3b3-b528-4f0c-a8da-fe4b4ceaa187.png)
